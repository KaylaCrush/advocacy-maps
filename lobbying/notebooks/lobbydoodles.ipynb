{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "class LobbyingDataPage:\n",
    "    lobbying_file = 'lobbying/data/lobbying.csv'\n",
    "    compensation_file = 'lobbying/data/compensation.csv'\n",
    "    contributions_file = 'lobbying/data/contributions.csv'\n",
    "\n",
    "    def __init__(self, html):\n",
    "        self.html = html\n",
    "        self.soup = bs(self.html,'html.parser')\n",
    "        if self.isValid():\n",
    "\n",
    "            self.is_entity = bool(self.soup.find('span', {'id': 'ContentPlaceHolder1_ERegistrationInfoReview1_lblEntityCompany'}))\n",
    "\n",
    "            self.company_name = self.get_company_name()\n",
    "            self.date_range = self.get_date_range()\n",
    "\n",
    "            if (self.soup.find('tr', {'class': 'GridHeader'})):\n",
    "                self.lobbying_data = self.extract_lobbying_data()\n",
    "                self.compensation_data = self.extract_compensation_data()\n",
    "                self.contributions_data = self.extract_contributions_data()\n",
    "\n",
    "        else:\n",
    "            self.default_values()\n",
    "\n",
    "    def isValid(self):\n",
    "        if \"An Error Occurred\" in self.soup.text:\n",
    "            return False\n",
    "\n",
    "    def default_values(self):\n",
    "            self.lobbying_data = pd.DataFrame()\n",
    "            self.compensation_data = pd.DataFrame()\n",
    "            self.contributions_data = pd.DataFrame()\n",
    "            self.company_name = ''\n",
    "\n",
    "    def get_date_range(self):\n",
    "        return self.soup.find('span', {'id': 'ContentPlaceHolder1_lblYear'}).text\n",
    "\n",
    "    def get_company_name(self):\n",
    "        if self.is_entity:\n",
    "            return self.soup.find('span', {'id': 'ContentPlaceHolder1_ERegistrationInfoReview1_lblEntityCompany'}).text\n",
    "        else:\n",
    "            return self.soup.find('span', {'id': 'ContentPlaceHolder1_LRegistrationInfoReview1_lblLobbyistCompany'}).text\n",
    "\n",
    "    def prep_tables(self):\n",
    "        some_tables = self.soup.find_all('tr', {'style': 'vertical-align: top'})\n",
    "\n",
    "        #Extract tables that contain the word 'lobbyist' and split at that word\n",
    "        if 'Lobbyist name' in some_tables[0].text:\n",
    "            split_tables = [table for table in some_tables if 'Client: ' in table.text][0].text.split('Client: ')\n",
    "        else:\n",
    "            split_tables = [table for table in some_tables if 'Lobbyist: ' in table.text][0].text.split('Lobbyist: ')\n",
    "        #Strip out junk\n",
    "        the_tables = [entry for entry in split_tables if entry.strip() and 'House / Senate' in entry]\n",
    "\n",
    "        clean_tables = []\n",
    "        for table in the_tables:\n",
    "            clean_table = [line for line in table.split('\\n') if line] # divide by lines and remove empties\n",
    "            clean_table = clean_table[:clean_table.index('\\xa0\\xa0\\xa0')] # Remove ending cruft\n",
    "            clean_tables.append(clean_table)\n",
    "\n",
    "        return clean_tables\n",
    "\n",
    "    def extract_lobbying_data(self):\n",
    "        if self.soup.find('span', {'id': 'ContentPlaceHolder1_LRegistrationInfoReview1_lblIncidental'}):\n",
    "            return pd.DataFrame()\n",
    "        clean_tables = self.prep_tables()\n",
    "        row_dicts = []\n",
    "\n",
    "        for table in clean_tables:\n",
    "            lobbyist_name = table[0].strip()\n",
    "            client_name = table[2].strip()\n",
    "            table_start_index = table.index('House / SenateBill Number or Agency NameBill title or activityAgent positionAmountDirect business association')+1\n",
    "            table_data = table[table_start_index:]\n",
    "\n",
    "            i=0\n",
    "            while i <= len(table_data)-8:\n",
    "                row_dicts.append({'LobbyingEntity': self.company_name,\n",
    "                                'DateRange': self.date_range,\n",
    "                                'Lobbyist': lobbyist_name,\n",
    "                                'Client': client_name,\n",
    "                                'House/Senate': table_data[i].strip(),\n",
    "                                'BillNumber':table_data[i+1].strip(),\n",
    "                                'BillActivity':table_data[i+2].strip(),\n",
    "                                'AgentPosition': table_data[i+3].strip(),\n",
    "                                'Amount': table_data[i+5].strip(),\n",
    "                                'DirectBusinessAssosciation': table_data[i+7].strip()})\n",
    "                i=i+8\n",
    "        return pd.DataFrame(row_dicts)\n",
    "\n",
    "    def extract_contributions_data(self):\n",
    "\n",
    "        bad_data = [element.split(\"Lobbyist: \")[0] for element in self.soup.text.split('Campaign Contributions') if \"DateLobbyist nameRecipient nameOffice soughtAmount\" in element]\n",
    "        if not bad_data:\n",
    "            print(\"NO DATA\")\n",
    "        pass1 = [element.split('Total contributions')[0] for element in bad_data]\n",
    "        pass2 = [element.split('soughtAmount\\n\\n')[1:][0] for element in pass1]\n",
    "        pass3 = \"\".join(pass2)\n",
    "        data = [element.strip() for element in pass3.split('\\n') if element.strip()]\n",
    "\n",
    "        i = 0\n",
    "        row_dicts = []\n",
    "        while i < len(data):\n",
    "            date = data[i].split()[0]\n",
    "            lobbyist = \" \".join(data[i].split()[1:])\n",
    "            recipient = data[i+1]\n",
    "            office = data[i+2]\n",
    "            amount = data[i+3]\n",
    "            row_dicts.append({  'LobbyingEntity': self.company_name,\n",
    "                                'DateRange': self.date_range,\n",
    "                                'Date': date,\n",
    "                                'LobbyistName': lobbyist,\n",
    "                                'RecipientName': recipient,\n",
    "                                'OfficeSought': office,\n",
    "                                'Amount': amount})\n",
    "            i=i+4\n",
    "\n",
    "        return pd.DataFrame(row_dicts)\n",
    "\n",
    "    def extract_compensation_data(self):\n",
    "        compensation_table = self.soup.find('table', {'id': 'ContentPlaceHolder1_DisclosureReviewDetail1_grdvClientPaidToEntity'})\n",
    "        if not bool(compensation_table):\n",
    "            return pd.DataFrame()\n",
    "        temp_list = [line.strip() for line in compensation_table.text.split('\\n') if line.strip()][1:-2]\n",
    "\n",
    "        temp_dict_list = []\n",
    "        for entry in temp_list:\n",
    "            if entry[0] != '$':\n",
    "                client_name = entry\n",
    "            else:\n",
    "                temp_dict_list.append({'LobbyingEntity': self.company_name, 'DateRange':self.date_range, 'Client': client_name, 'Amount':entry})\n",
    "        return pd.DataFrame(temp_dict_list)\n",
    "\n",
    "    def save(self):\n",
    "        if not self.lobbying_data.empty:\n",
    "            self.write_data(LobbyingDataPage.lobbying_file, self.lobbying_data)\n",
    "        if not self.compensation_data.empty:\n",
    "            self.write_data(LobbyingDataPage.compensation_file, self.compensation_data)\n",
    "        if not self.contributions_data.empty:\n",
    "            self.write_data(LobbyingDataPage.contributions_file, self.contributions_data)\n",
    "\n",
    "    def write_data(self, file_path, dataframe):\n",
    "        write = True\n",
    "        #if os.path.exists(file_path):\n",
    "        with open(file_path, mode = 'a', encoding = 'utf-8') as f:\n",
    "            for line in f:\n",
    "                if self.company_name in line and self.date_range in line:\n",
    "                    print('Data already present in ' + file_path)\n",
    "                    write = False\n",
    "                    break\n",
    "\n",
    "        if write and type(dataframe) == pd.DataFrame:\n",
    "            print('Saving data to ' + file_path)\n",
    "            dataframe.to_csv(file_path, mode ='a+',header=(not os.path.exists(file_path)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save(html_list):\n",
    "    #for html in html_list:\n",
    "        #LobbyingDataPage(html).save()\n",
    "    for i in range(len(html_list)):\n",
    "        print(\"Saving \"+str(i))\n",
    "        LobbyingDataPage(html_list[i]).save()\n",
    "\n",
    "def pull_data(url):\n",
    "    headers={\"User-Agent\": \"Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148\"}\n",
    "    result = requests.get(url, headers=headers)\n",
    "    result.raise_for_status()\n",
    "    return result.content\n",
    "\n",
    "def download_html_list(url_list):\n",
    "    html_list = []\n",
    "    for url in url_list:\n",
    "        print(\"Pulling data from \" + url)\n",
    "        html_list.append(pull_data(url))\n",
    "    return html_list\n",
    "\n",
    "def save_data_from_url_list(url_list):\n",
    "    disclosure_links = extract_and_save(download_html_list(url_list))\n",
    "    html_list = download_html_list(disclosure_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def extract_client_links(year):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    url = 'https://www.sec.state.ma.us/LobbyistPublicSearch/Default.aspx'\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element('id','ContentPlaceHolder1_rdbSearchByType').click()\n",
    "    select = Select(driver.find_element(By.CLASS_NAME,'p3'))\n",
    "\n",
    "    select.select_by_value(year)\n",
    "    Select(driver.find_element('id','ContentPlaceHolder1_ucSearchCriteriaByType_drpType')).select_by_value('L')\n",
    "    driver.find_element('id','ContentPlaceHolder1_btnSearch').click()\n",
    "\n",
    "    find_table = driver.find_element(By.ID,'ContentPlaceHolder1_ucSearchResultByTypeAndCategory_grdvSearchResultByTypeAndCategory')\n",
    "    links = find_table.find_elements(By.TAG_NAME,'a')\n",
    "    links_list = [l.get_attribute('href') for l in links if str(l.get_attribute('href')).startswith('javascript') == False]\n",
    "    driver.quit()\n",
    "    return links_list\n",
    "\n",
    "def extract_disclosures(list_of_links):\n",
    "    disclosure_reports = []\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    for link in list_of_links:\n",
    "    # print(link)\n",
    "        driver.get(link)\n",
    "        all_links = driver.find_elements(By.CLASS_NAME,'BlueLinks')\n",
    "        disclosure_links = [l.get_attribute('href') for l in all_links if 'CompleteDisclosure' in l.get_attribute('href')]\n",
    "        for dl in disclosure_links:\n",
    "            disclosure_reports.append(dl)\n",
    "    driver.quit()\n",
    "\n",
    "    return disclosure_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "disclosure_links = extract_disclosures(extract_client_links('2020'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_list = download_html_list(disclosure_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2020html.pkl\", \"wb\") as f:\n",
    "    pickle.dump(html_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(html_list)):\n",
    "    ldp = LobbyingDataPage(html_list[i])\n",
    "    print(ldp.company_name)\n",
    "    print(ldp.compensation_data)\n",
    "    print(ldp.contributions_data)\n",
    "    print(ldp.lobbying_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_list[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving 0\n",
      "Saving 1\n",
      "Saving 2\n",
      "Saving 3\n",
      "Saving 4\n",
      "Saving 5\n",
      "Saving 6\n",
      "Saving 7\n",
      "Saving 8\n",
      "Saving 9\n",
      "Saving 10\n",
      "Saving 11\n",
      "Saving 12\n",
      "Saving 13\n",
      "Saving 14\n",
      "Saving 15\n",
      "Saving 16\n",
      "Saving 17\n",
      "Saving 18\n",
      "Saving 19\n",
      "Saving 20\n",
      "Saving 21\n",
      "Saving 22\n",
      "Saving 23\n",
      "Saving 24\n",
      "Saving 25\n",
      "Saving 26\n",
      "Saving 27\n",
      "Saving 28\n",
      "Saving 29\n",
      "Saving 30\n",
      "Saving 31\n",
      "Saving 32\n",
      "Saving 33\n",
      "Saving 34\n",
      "Saving 35\n",
      "Saving 36\n",
      "Saving 37\n",
      "Saving 38\n",
      "Saving 39\n",
      "Saving 40\n",
      "Saving 41\n",
      "Saving 42\n",
      "Saving 43\n",
      "Saving 44\n",
      "Saving 45\n",
      "Saving 46\n",
      "Saving 47\n",
      "Saving 48\n",
      "Saving 49\n",
      "Saving 50\n",
      "Saving 51\n",
      "Saving 52\n",
      "Saving 53\n",
      "Saving 54\n",
      "Saving 55\n",
      "Saving 56\n",
      "Saving 57\n",
      "Saving 58\n",
      "Saving 59\n",
      "Saving 60\n",
      "Saving 61\n",
      "Saving 62\n",
      "Saving 63\n",
      "Saving 64\n",
      "Saving 65\n",
      "Saving 66\n",
      "Saving 67\n",
      "Saving 68\n",
      "Saving 69\n",
      "Saving 70\n",
      "Saving 71\n",
      "Saving 72\n",
      "Saving 73\n",
      "Saving 74\n",
      "Saving 75\n",
      "Saving 76\n",
      "Saving 77\n",
      "Saving 78\n",
      "Saving 79\n",
      "Saving 80\n",
      "Saving 81\n",
      "Saving 82\n",
      "Saving 83\n",
      "Saving 84\n",
      "Saving 85\n",
      "Saving 86\n",
      "Saving 87\n",
      "Saving 88\n",
      "Saving 89\n",
      "Saving 90\n",
      "Saving 91\n",
      "Saving 92\n",
      "Saving 93\n",
      "Saving 94\n",
      "Saving 95\n",
      "Saving 96\n",
      "Saving 97\n",
      "Saving 98\n",
      "Saving 99\n",
      "Saving 100\n",
      "Saving 101\n",
      "Saving 102\n",
      "Saving 103\n",
      "Saving 104\n",
      "Saving 105\n",
      "Saving 106\n",
      "Saving 107\n",
      "Saving 108\n",
      "Saving 109\n",
      "Saving 110\n",
      "Saving 111\n",
      "Saving 112\n",
      "Saving 113\n",
      "Saving 114\n",
      "Saving 115\n",
      "Saving 116\n",
      "Saving 117\n",
      "Saving 118\n",
      "Saving 119\n",
      "Saving 120\n",
      "Saving 121\n",
      "Saving 122\n",
      "Saving 123\n",
      "Saving 124\n",
      "Saving 125\n",
      "Saving 126\n",
      "Saving 127\n",
      "Saving 128\n",
      "Saving 129\n",
      "Saving 130\n",
      "Saving 131\n",
      "Saving 132\n",
      "Saving 133\n",
      "Saving 134\n",
      "Saving 135\n",
      "Saving 136\n",
      "Saving 137\n",
      "Saving 138\n",
      "Saving 139\n",
      "Saving 140\n",
      "Saving 141\n",
      "Saving 142\n",
      "Saving 143\n",
      "Saving 144\n",
      "Saving 145\n",
      "Saving 146\n",
      "Saving 147\n",
      "Saving 148\n",
      "Saving 149\n",
      "Saving 150\n",
      "Saving 151\n",
      "Saving 152\n",
      "Saving 153\n",
      "Saving 154\n",
      "Saving 155\n",
      "Saving 156\n",
      "Saving 157\n",
      "Saving 158\n",
      "Saving 159\n",
      "Saving 160\n",
      "Saving 161\n",
      "Saving 162\n",
      "Saving 163\n",
      "Saving 164\n",
      "Saving 165\n",
      "Saving 166\n",
      "Saving 167\n",
      "Saving 168\n",
      "Saving 169\n",
      "Saving 170\n"
     ]
    }
   ],
   "source": [
    "extract_and_save(html_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8ofjpjJ5oC9yekMB3UEgH8iaJQ382jQKJduWUUjX27ANT'"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disclosure_links[45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2005html.pkl\", \"rb\") as f:\n",
    "    html05 = pickle.load(f)\n",
    "with open(\"2020html.pkl\", \"rb\") as f:\n",
    "    html20 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "errorpage = html05[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\r\\n\\r\\n<html xmlns=\"http://www.w3.org/1999/xhtml\" >\\r\\n<head><meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\" /><link href=\"/css/styleapps.css?version=060622\" rel=\"stylesheet\" type=\"text/css\" meta=\"screen\" /><link href=\"/css/topnav.css?version=060622\" rel=\"stylesheet\" type=\"text/css\" meta=\"screen\" /><link rel=\"shortcut icon\" href=\"/images/favicon.gif\" type=\"image/x-icon\" />\\r\\n<script type=\"text/javascript\" src=\"/js/p7TMMscripts.js\"></script>\\r\\n<script type=\"text/javascript\" src=\"/js/google_analytics.js\"></script>\\r\\n<link href=\"/css/p7TMM04.css\" rel=\"stylesheet\" type=\"text/css\" media=\"all\" />\\r\\n\\r\\n<!--[if lt IE 8]><link rel=\"stylesheet\" type=\"text/css\" href=\"/css/lt8.css\" /><![endif]-->\\r\\n<title>\\r\\n\\tLobbyist Public Search\\r\\n</title><link href=\"css/StyleSheet.css\" type=\"text/css\" rel=\"stylesheet\" />\\r\\n    <script language=\"javascript\" src=\"../Javascript/Help.js\" type=\"text/javascript\"></script>\\r\\n</head>\\r\\n<body class=\"body\">\\r\\n    <div id=\"outer\">\\r\\n\\t\\t<div id=\"header\" role=\"banner\"> <img src=\"/images/header.gif\" alt=\"William Francis Galvin, Secretary of the Commonwealth of Massachusetts\" width=\"960px\" height=\"146px\" class=\"mobile_display_none\"/> </div>\\r\\n\\t\\t<div id=\"wrapper\">\\r\\n\\t\\t<div id=\"dolphincontainer\">\\r\\n\\r\\n  <div id=\"dolphinnav\" role=\"navigation\" aria-label=\"global links\">\\r\\n    <ul>\\r\\n      <li id=\"nav-home\"><a href=\"https://www.sec.state.ma.us/index.htm\"><span>Home</span></a></li>\\r\\n      <li id=\"nav-directions\"><a href=\"https://www.sec.state.ma.us/secdir.htm\"><span>Directions</span></a></li>\\r\\n      <li id=\"nav-contact\"><a href=\"https://www.sec.state.ma.us/seccon.htm\"><span>Contact Us</span></a></li>\\r\\n    </ul>\\r\\n  </div>\\r\\n  \\r\\n  <!--Search using Swiftype-->\\r\\n  <div id=\"search\" role=\"search\" aria-label=\"Search field\">\\r\\n      <form>\\r\\n      <input type=\"text\"  class=\"st-default-search-input\">\\r\\n      </form>\\r\\n    \\r\\n  </div>\\r\\n</div>\\r\\n<form method=\"post\" action=\"./ErrorPage.aspx?aspxerrorpath=%2fLobbyistPublicSearch%2fCompleteDisclosure.aspx\" id=\"form1\">\\r\\n<div class=\"aspNetHidden\">\\r\\n<input type=\"hidden\" name=\"__VIEWSTATE\" id=\"__VIEWSTATE\" value=\"/wEPDwUKMTU0ODQyNTcyNw9kFgJmD2QWAgIGD2QWAgIBD2QWBgIBDw8WAh4LTmF2aWdhdGVVcmwFLS9Mb2JieWlzdFB1YmxpY1NlYXJjaC9Db21wbGV0ZURpc2Nsb3N1cmUuYXNweGQWAmYPFgIeBFRleHQFLS9Mb2JieWlzdFB1YmxpY1NlYXJjaC9Db21wbGV0ZURpc2Nsb3N1cmUuYXNweGQCAw8PFgIeB1Zpc2libGVoZGQCBw8PFgIfAmhkZGRbkHwIflB1Clb99JDjmvZ2F+FItL9NXvsouKd7Hf0KZQ==\" />\\r\\n</div>\\r\\n\\r\\n<div class=\"aspNetHidden\">\\r\\n\\r\\n\\t<input type=\"hidden\" name=\"__VIEWSTATEGENERATOR\" id=\"__VIEWSTATEGENERATOR\" value=\"08F4BE82\" />\\r\\n</div>\\r\\n           <div style=\"background-color: White\">\\r\\n                <table class=\"CenterAligned\" style=\"width: 960px; margin-left: auto; margin-right:auto; background-color:#ffffff\" cellpadding=\"0\" cellspacing=\"0\"> \\r\\n                    <tr>\\r\\n\\t\\t\\t            <td style=\"font: bold 22pt arial; text-align: center; vertical-align: top; padding-top: 24px; padding-bottom: 12px\" >\\r\\n\\t\\t\\t            Lobbyist Public Search</td>\\r\\n\\t\\t\\t        </tr>\\r\\n\\t\\t\\t        <tr>\\r\\n                        <td valign=\"top\">\\r\\n                            \\r\\n    <table border=\"0\" width=\"100%\">\\r\\n        <tr><td width=\"5%\">&nbsp;</td>\\r\\n            <td>\\r\\n                <table bgcolor=\"#003366\" cellpadding=\"0\" cellspacing=\"2\" border=\"0\" width=\"100%\">\\r\\n\\t            <tr><td>\\r\\n\\t\\t            <table bgcolor=\"#ffffff\" cellpadding=\"4\" cellspacing=\"0\" border=\"0\" width=\"100%\">\\r\\n\\t\\t                <tr><td>\\r\\n\\t\\t\\t                <h1>An Error Occurred</h1>\\r\\n\\t\\t                </td></tr>\\r\\n\\t\\t            </table>\\r\\n\\t            </td></tr></table>\\r\\n\\r\\n                <p>\\r\\n                There was a problem opening \\r\\n                <strong><a id=\"ContentPlaceHolder1_Hyperlink1\" href=\"/LobbyistPublicSearch/CompleteDisclosure.aspx\">/LobbyistPublicSearch/CompleteDisclosure.aspx</a></strong>.<br />\\r\\n                If problem persists, please contact the administrator.<br />\\r\\n\\t            You could go <a href=\"javascript:history.go(-1)\">back</a> and try again, or perhaps return to the <a href=\"/\" title=\"Home Page\">Home Page</a>. </p>\\r\\n\\t            <br />\\r\\n\\r\\n                \\r\\n            </td>\\r\\n            <td width=\"5%\">&nbsp;</td>\\r\\n        </tr>\\r\\n    </table>\\r\\n\\r\\n                        </td>\\r\\n                    </tr>\\r\\n                    <tr>\\r\\n                        <td>\\r\\n                            <div class=\"body2010\">\\r\\n                                <table style=\"background-color: #ffffff; width: 100%\" border=\"0\" cellspacing=\"0\" cellpadding=\"4\" >\\r\\n                                    <tr class=\"SolidBlueBoxFooter\">\\r\\n                                        <td align=\"left\">\\r\\n                                            Lobbyist Division, Office of the Secretary of the Commonwealth of Massachusetts\\r\\n                                        </td>\\r\\n                                        \\r\\n                                        <td align=\"center\">\\r\\n                                            <a id=\"HyperLink5\" class=\"WhiteLinks\" href=\"https://www.sec.state.ma.us/LobbyistWeb/ReadMe/ContactInfo.aspx\" target=\"_blank\">Contact the Lobbyist Division</a>\\r\\n                                        </td>\\r\\n                                    </tr>\\r\\n                                </table>\\r\\n                            </div>\\r\\n                        </td>\\r\\n                    </tr>\\r\\n                </table>\\r\\n            </div>\\r\\n        </form>\\r\\n        </div>\\r\\n\\t\\t <div id=\"footer\" role=\"contentinfo\">\\r\\n <p class=\"footer-text\">William Francis Galvin, Secretary of the Commonwealth of Massachusetts</p>\\r\\n <p class=\"footer-text\"><a href=\"https://www.sec.state.ma.us/sectandc.htm\" target=\"_blank\">Terms and Conditions</a></p>\\r\\n <p class=\"footer-text\"><a href=\"https://www.sec.state.ma.us/secaccessibility.htm\" target=\"_blank\">Accessibility Statement</a></p>\\r\\n <br />\\r\\n </div>\\r\\n\\r\\n<script type=\"text/javascript\">\\r\\n  (function(w,d,t,u,n,s,e){w[\\'SwiftypeObject\\']=n;w[n]=w[n]||function(){\\r\\n  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);\\r\\n  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);\\r\\n  })(window,document,\\'script\\',\\'//s.swiftypecdn.com/install/v2/st.js\\',\\'_st\\');\\r\\n  \\r\\n  _st(\\'install\\',\\'yhM-dJN9ivmq2ByN21Yn\\',\\'2.0.0\\');\\r\\n</script>\\r\\n\\t</div>\\r\\n<script async type=\"text/javascript\" src=\"/_Incapsula_Resource?SWJIYLWA=719d34d31c8e3a6e6fffd425f7e032f3&ns=1&cb=218690363\"></script>\\n</body>\\r\\n</html>\\r\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errorpage.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"indivlobbyist.html\", \"w\") as f:\n",
    "    f.write(html05[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = bs(html_list[0], 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\geekc\\Code\\jigsaw\\Intern Stuff\\advocacy-maps\\lobbying\\notebooks\\lobbydoodles.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dfs[\u001b[39m4\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m  Business name\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39mLobbyist name  \u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "dfs[4][0][3].split('  Business name')[0].split('Lobbyist name  ')[1].replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\geekc\\Code\\jigsaw\\Intern Stuff\\advocacy-maps\\lobbying\\notebooks\\lobbydoodles.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m date_range \u001b[39m=\u001b[39m dfs[\u001b[39m4\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m2\u001b[39m]\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:  \u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m lobbyist_name \u001b[39m=\u001b[39m dfs[\u001b[39m4\u001b[39;49m][\u001b[39m0\u001b[39;49m][\u001b[39m3\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39m Business name\u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49msplit(\u001b[39m'\u001b[39;49m\u001b[39mLobbyist name  \u001b[39;49m\u001b[39m'\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39mreplace(\u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "date_range = dfs[4][0][2].split(\":  \")[1].replace(\"  \", \" \")\n",
    "lobbyist_name = dfs[4][0][3].split(' Business name')[0].split('Lobbyist name  ')[1].replace(\"  \", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01/01/2020 - 06/30/2020'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    if len(df.columns) == 3 and (df.columns == ['Date', 'Activity or Bill No and Title', 'Client represented']).all():\n",
    "        lobbying_data = df\n",
    "    elif len(df.columns) == 4 and (df.columns == ['Date', 'Recipient name', 'Office sought', 'Amount']).all():\n",
    "        contribution_data = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Activity or Bill No and Title</th>\n",
       "      <th>Client represented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1/05-6/28/05</td>\n",
       "      <td>S.560, S.565, S.582, S.738, S.2042, S.2043, S....</td>\n",
       "      <td>Blue Cross Blue Shield of Massachusetts</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date                      Activity or Bill No and Title  \\\n",
       "0  1/05-6/28/05  S.560, S.565, S.582, S.738, S.2042, S.2043, S....   \n",
       "\n",
       "                        Client represented  \n",
       "0  Blue Cross Blue Shield of Massachusetts  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lobbying_data\n",
    "# TODO handle situation where activity or bill no and title is multiple things for one client\n",
    "# basically do a new line for each bill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs[9] = df\n",
    "df.columns == ['Date', 'Activity or Bill No and Title', 'Client represented']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LobbyingDataPage:\n",
    "    lobbying_file = 'lobbying/data/lobbying.csv'\n",
    "    compensation_file = 'lobbying/data/compensation.csv'\n",
    "    contributions_file = 'lobbying/data/contributions.csv'\n",
    "\n",
    "    def __init__(self, html):\n",
    "        self.html = html\n",
    "        self.soup = bs(self.html,'html.parser')\n",
    "        \n",
    "        if self.isValid():\n",
    "            self.extract_data()\n",
    "        \n",
    "        else:\n",
    "            self.set_defaults()\n",
    "\n",
    "    def isValid(self):\n",
    "        if \"An Error Occurred\" in self.soup.text:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def extract_data(self):\n",
    "        self.company_name = self.get_company_name()\n",
    "        self.date_range = self.get_date_range()\n",
    "        self.lobbying_data = self.extract_lobbying_data()\n",
    "        self.compensation_data = self.extract_compensation_data()\n",
    "        self.contributions_data = self.extract_contributions_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_entity_urls = ['https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oUX2F0/qMX8aZhXGSqISnPo81sWNBWPRVYkBCJOoiSOC',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oSXfp14ycsC4C75XzUXuOD0RNTxP5RQlQYtqqNlG19gK',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Kce7BzXCV/xrL2hRhIeiyrKq4598/MmeOqNxcRw3anF8llP1KzXu6cA+wFHr/nIU',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Tcg7Il3rjW5sIbUrwbcVKYqHMk7FN1E+JyuG2w4SuGbSUM5P5U7i1R+Kl69eLgqM']\n",
    "\n",
    "test_lobbyist_urls = ['https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oazP9bD0a9KMVAPrqT2Yinwr4JTgsyzaInIK/BXJHlV1',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oWE66BrPrRKWkGd1M0SOekxiCPdVzrEEIQIimWwrunVO',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=v/mjLQ41YVqm2bof1TANC8QjRgi8rX5lY/Ozmu5hJvE2+nv22rfxUQCNlsde/z4F',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=qOH5OAu6URrG3qvY0KcrjT8Cd6HIk4OEVgmMDn8i9vU6n8cVsZ6PiBz3uD4tmhUG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_entity_htmls = download_html_list(test_entity_urls)\n",
    "test_lobbyist_htmls = download_html_list(test_lobbyist_urls)\n",
    "html_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.read_html(test_entity_htmls[0])\n",
    "ldf = pd.read_html(test_lobbyist_htmls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Disclosure reporting details</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Back to search detail summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lobbyist disclosure reporting period:  01/01/2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lobbyist name  Leda  Anderson  Business name  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Operating Expenses  No operating expenses were...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0                       Disclosure reporting details\n",
       "1                      Back to search detail summary\n",
       "2  Lobbyist disclosure reporting period:  01/01/2...\n",
       "3  Lobbyist name  Leda  Anderson  Business name  ...\n",
       "4  Operating Expenses  No operating expenses were..."
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(html05)):\n",
    "    df = pd.read_html(html05[i])\n",
    "    print(i)\n",
    "    is_entity = 'Entity' in df[4][0][2]\n",
    "    is_valid = 'disclosure' in df[4][0][2]\n",
    "    if not is_valid:\n",
    "        print('HAHA WHAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_html(html05[0])\n",
    "'An Error Occurred' in str(dfs[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html05[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 48\n",
      "Error processing index 54\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(html05)):\n",
    "    dfs = pd.read_html(html05[i])\n",
    "    is_error = 'An Error Occurred' in str(dfs[0][0])\n",
    "    if is_error:\n",
    "        print(f'Error processing index {i}')\n",
    "        #Return\n",
    "    else: #Remove\n",
    "        is_entity = 'Entity' in dfs[4][0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header:\n",
    "# Authorizing Officer name / Lobbyist name\n",
    "# Title / NA\n",
    "# Business name / Business name\n",
    "# Address / Address\n",
    "# City, state, zip code / Citym, state, zip code\n",
    "# country / country\n",
    "# NA / Agent Type\n",
    "\n",
    "#TABLES:\n",
    "# Entities\n",
    "# Lobbyists\n",
    "# Client Compensation\n",
    "# Compensation/Salaries Paid\n",
    "# Activities, Bill Numbers and Titles\n",
    "# Operating Expenses\n",
    "# Meals, Travel, and Entertainment Expenses\n",
    "# Additional Expenses\n",
    "# Campaign Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "300fbccfaa1afd04bb86653fbdee52f26c731e37f5150715ebdacf05ee18f2ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "\n",
    "class LobbyingDataPage:\n",
    "    lobbying_file = 'lobbying/data/lobbying.csv'\n",
    "    compensation_file = 'lobbying/data/compensation.csv'\n",
    "    contributions_file = 'lobbying/data/contributions.csv'\n",
    "\n",
    "    def __init__(self, html):\n",
    "        self.html = html\n",
    "        self.soup = bs(self.html,'html.parser')\n",
    "        if self.isValid():\n",
    "\n",
    "            self.is_entity = bool(self.soup.find('span', {'id': 'ContentPlaceHolder1_ERegistrationInfoReview1_lblEntityCompany'}))\n",
    "\n",
    "            self.company_name = self.get_company_name()\n",
    "            self.date_range = self.get_date_range()\n",
    "\n",
    "            if (self.soup.find('tr', {'class': 'GridHeader'})):\n",
    "                self.lobbying_data = self.extract_lobbying_data()\n",
    "                self.compensation_data = self.extract_compensation_data()\n",
    "                self.contributions_data = self.extract_contributions_data()\n",
    "\n",
    "        else:\n",
    "            self.default_values()\n",
    "\n",
    "    def isValid(self):\n",
    "        if \"An Error Occurred\" in self.soup.text:\n",
    "            return False\n",
    "\n",
    "    def default_values(self):\n",
    "            self.lobbying_data = pd.DataFrame()\n",
    "            self.compensation_data = pd.DataFrame()\n",
    "            self.contributions_data = pd.DataFrame()\n",
    "            self.company_name = ''\n",
    "\n",
    "    def get_date_range(self):\n",
    "        return self.soup.find('span', {'id': 'ContentPlaceHolder1_lblYear'}).text\n",
    "\n",
    "    def get_company_name(self):\n",
    "        if self.is_entity:\n",
    "            return self.soup.find('span', {'id': 'ContentPlaceHolder1_ERegistrationInfoReview1_lblEntityCompany'}).text\n",
    "        else:\n",
    "            return self.soup.find('span', {'id': 'ContentPlaceHolder1_LRegistrationInfoReview1_lblLobbyistCompany'}).text\n",
    "\n",
    "    def prep_tables(self):\n",
    "        some_tables = self.soup.find_all('tr', {'style': 'vertical-align: top'})\n",
    "\n",
    "        #Extract tables that contain the word 'lobbyist' and split at that word\n",
    "        if 'Lobbyist name' in some_tables[0].text:\n",
    "            split_tables = [table for table in some_tables if 'Client: ' in table.text][0].text.split('Client: ')\n",
    "        else:\n",
    "            split_tables = [table for table in some_tables if 'Lobbyist: ' in table.text][0].text.split('Lobbyist: ')\n",
    "        #Strip out junk\n",
    "        the_tables = [entry for entry in split_tables if entry.strip() and 'House / Senate' in entry]\n",
    "\n",
    "        clean_tables = []\n",
    "        for table in the_tables:\n",
    "            clean_table = [line for line in table.split('\\n') if line] # divide by lines and remove empties\n",
    "            clean_table = clean_table[:clean_table.index('\\xa0\\xa0\\xa0')] # Remove ending cruft\n",
    "            clean_tables.append(clean_table)\n",
    "\n",
    "        return clean_tables\n",
    "\n",
    "    def extract_lobbying_data(self):\n",
    "        if self.soup.find('span', {'id': 'ContentPlaceHolder1_LRegistrationInfoReview1_lblIncidental'}):\n",
    "            return pd.DataFrame()\n",
    "        clean_tables = self.prep_tables()\n",
    "        row_dicts = []\n",
    "\n",
    "        for table in clean_tables:\n",
    "            lobbyist_name = table[0].strip()\n",
    "            client_name = table[2].strip()\n",
    "            table_start_index = table.index('House / SenateBill Number or Agency NameBill title or activityAgent positionAmountDirect business association')+1\n",
    "            table_data = table[table_start_index:]\n",
    "\n",
    "            i=0\n",
    "            while i <= len(table_data)-8:\n",
    "                row_dicts.append({'LobbyingEntity': self.company_name,\n",
    "                                'DateRange': self.date_range,\n",
    "                                'Lobbyist': lobbyist_name,\n",
    "                                'Client': client_name,\n",
    "                                'House/Senate': table_data[i].strip(),\n",
    "                                'BillNumber':table_data[i+1].strip(),\n",
    "                                'BillActivity':table_data[i+2].strip(),\n",
    "                                'AgentPosition': table_data[i+3].strip(),\n",
    "                                'Amount': table_data[i+5].strip(),\n",
    "                                'DirectBusinessAssosciation': table_data[i+7].strip()})\n",
    "                i=i+8\n",
    "        return pd.DataFrame(row_dicts)\n",
    "\n",
    "    def extract_contributions_data(self):\n",
    "\n",
    "        bad_data = [element.split(\"Lobbyist: \")[0] for element in self.soup.text.split('Campaign Contributions') if \"DateLobbyist nameRecipient nameOffice soughtAmount\" in element]\n",
    "        if not bad_data:\n",
    "            print(\"NO DATA\")\n",
    "        pass1 = [element.split('Total contributions')[0] for element in bad_data]\n",
    "        pass2 = [element.split('soughtAmount\\n\\n')[1:][0] for element in pass1]\n",
    "        pass3 = \"\".join(pass2)\n",
    "        data = [element.strip() for element in pass3.split('\\n') if element.strip()]\n",
    "\n",
    "        i = 0\n",
    "        row_dicts = []\n",
    "        while i < len(data):\n",
    "            date = data[i].split()[0]\n",
    "            lobbyist = \" \".join(data[i].split()[1:])\n",
    "            recipient = data[i+1]\n",
    "            office = data[i+2]\n",
    "            amount = data[i+3]\n",
    "            row_dicts.append({  'LobbyingEntity': self.company_name,\n",
    "                                'DateRange': self.date_range,\n",
    "                                'Date': date,\n",
    "                                'LobbyistName': lobbyist,\n",
    "                                'RecipientName': recipient,\n",
    "                                'OfficeSought': office,\n",
    "                                'Amount': amount})\n",
    "            i=i+4\n",
    "\n",
    "        return pd.DataFrame(row_dicts)\n",
    "\n",
    "    def extract_compensation_data(self):\n",
    "        compensation_table = self.soup.find('table', {'id': 'ContentPlaceHolder1_DisclosureReviewDetail1_grdvClientPaidToEntity'})\n",
    "        if not bool(compensation_table):\n",
    "            return pd.DataFrame()\n",
    "        temp_list = [line.strip() for line in compensation_table.text.split('\\n') if line.strip()][1:-2]\n",
    "\n",
    "        temp_dict_list = []\n",
    "        for entry in temp_list:\n",
    "            if entry[0] != '$':\n",
    "                client_name = entry\n",
    "            else:\n",
    "                temp_dict_list.append({'LobbyingEntity': self.company_name, 'DateRange':self.date_range, 'Client': client_name, 'Amount':entry})\n",
    "        return pd.DataFrame(temp_dict_list)\n",
    "\n",
    "    def save(self):\n",
    "        if not self.lobbying_data.empty:\n",
    "            self.write_data(LobbyingDataPage.lobbying_file, self.lobbying_data)\n",
    "        if not self.compensation_data.empty:\n",
    "            self.write_data(LobbyingDataPage.compensation_file, self.compensation_data)\n",
    "        if not self.contributions_data.empty:\n",
    "            self.write_data(LobbyingDataPage.contributions_file, self.contributions_data)\n",
    "\n",
    "    def write_data(self, file_path, dataframe):\n",
    "        write = True\n",
    "        #if os.path.exists(file_path):\n",
    "        with open(file_path, mode = 'a', encoding = 'utf-8') as f:\n",
    "            for line in f:\n",
    "                if self.company_name in line and self.date_range in line:\n",
    "                    print('Data already present in ' + file_path)\n",
    "                    write = False\n",
    "                    break\n",
    "\n",
    "        if write and type(dataframe) == pd.DataFrame:\n",
    "            print('Saving data to ' + file_path)\n",
    "            dataframe.to_csv(file_path, mode ='a+',header=(not os.path.exists(file_path)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_and_save(html_list):\n",
    "    #for html in html_list:\n",
    "        #LobbyingDataPage(html).save()\n",
    "    for i in range(len(html_list)):\n",
    "        print(\"Saving \"+str(i))\n",
    "        LobbyingDataPage(html_list[i]).save()\n",
    "\n",
    "def pull_data(url):\n",
    "    headers={\"User-Agent\": \"Mozilla/5.0 (iPad; CPU OS 12_2 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Mobile/15E148\"}\n",
    "    result = requests.get(url, headers=headers)\n",
    "    result.raise_for_status()\n",
    "    return result.content\n",
    "\n",
    "def download_html_list(url_list):\n",
    "    html_list = []\n",
    "    for url in url_list:\n",
    "        print(\"Pulling data from \" + url)\n",
    "        html_list.append(pull_data(url))\n",
    "    return html_list\n",
    "\n",
    "def save_data_from_url_list(url_list):\n",
    "    disclosure_links = extract_and_save(download_html_list(url_list))\n",
    "    html_list = download_html_list(disclosure_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "def extract_client_links(year):\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "    url = 'https://www.sec.state.ma.us/LobbyistPublicSearch/Default.aspx'\n",
    "\n",
    "    driver.get(url)\n",
    "\n",
    "    driver.find_element('id','ContentPlaceHolder1_rdbSearchByType').click()\n",
    "    select = Select(driver.find_element(By.CLASS_NAME,'p3'))\n",
    "\n",
    "    select.select_by_value(year)\n",
    "    Select(driver.find_element('id','ContentPlaceHolder1_ucSearchCriteriaByType_drpType')).select_by_value('L')\n",
    "    driver.find_element('id','ContentPlaceHolder1_btnSearch').click()\n",
    "\n",
    "    find_table = driver.find_element(By.ID,'ContentPlaceHolder1_ucSearchResultByTypeAndCategory_grdvSearchResultByTypeAndCategory')\n",
    "    links = find_table.find_elements(By.TAG_NAME,'a')\n",
    "    links_list = [l.get_attribute('href') for l in links if str(l.get_attribute('href')).startswith('javascript') == False]\n",
    "    driver.quit()\n",
    "    return links_list\n",
    "\n",
    "def extract_disclosures(list_of_links):\n",
    "    disclosure_reports = []\n",
    "\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()))\n",
    "\n",
    "    for link in list_of_links:\n",
    "    # print(link)\n",
    "        driver.get(link)\n",
    "        all_links = driver.find_elements(By.CLASS_NAME,'BlueLinks')\n",
    "        disclosure_links = [l.get_attribute('href') for l in all_links if 'CompleteDisclosure' in l.get_attribute('href')]\n",
    "        for dl in disclosure_links:\n",
    "            disclosure_reports.append(dl)\n",
    "    driver.quit()\n",
    "\n",
    "    return disclosure_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"2005html.pkl\", \"rb\") as f:\n",
    "    html05 = pickle.load(f)\n",
    "with open(\"2020html.pkl\", \"rb\") as f:\n",
    "    html20 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"indivlobbyist.html\", \"w\") as f:\n",
    "    f.write(html05[0].decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_entity_urls = ['https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oUX2F0/qMX8aZhXGSqISnPo81sWNBWPRVYkBCJOoiSOC',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oSXfp14ycsC4C75XzUXuOD0RNTxP5RQlQYtqqNlG19gK',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Kce7BzXCV/xrL2hRhIeiyrKq4598/MmeOqNxcRw3anF8llP1KzXu6cA+wFHr/nIU',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Tcg7Il3rjW5sIbUrwbcVKYqHMk7FN1E+JyuG2w4SuGbSUM5P5U7i1R+Kl69eLgqM']\n",
    "\n",
    "test_lobbyist_urls = ['https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oazP9bD0a9KMVAPrqT2Yinwr4JTgsyzaInIK/BXJHlV1',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oWE66BrPrRKWkGd1M0SOekxiCPdVzrEEIQIimWwrunVO',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=v/mjLQ41YVqm2bof1TANC8QjRgi8rX5lY/Ozmu5hJvE2+nv22rfxUQCNlsde/z4F',\n",
    "    'https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=qOH5OAu6URrG3qvY0KcrjT8Cd6HIk4OEVgmMDn8i9vU6n8cVsZ6PiBz3uD4tmhUG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oUX2F0/qMX8aZhXGSqISnPo81sWNBWPRVYkBCJOoiSOC\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oSXfp14ycsC4C75XzUXuOD0RNTxP5RQlQYtqqNlG19gK\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Kce7BzXCV/xrL2hRhIeiyrKq4598/MmeOqNxcRw3anF8llP1KzXu6cA+wFHr/nIU\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=Tcg7Il3rjW5sIbUrwbcVKYqHMk7FN1E+JyuG2w4SuGbSUM5P5U7i1R+Kl69eLgqM\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oazP9bD0a9KMVAPrqT2Yinwr4JTgsyzaInIK/BXJHlV1\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=eaiHDZ6kDM3fHlDyBbc8oWE66BrPrRKWkGd1M0SOekxiCPdVzrEEIQIimWwrunVO\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=v/mjLQ41YVqm2bof1TANC8QjRgi8rX5lY/Ozmu5hJvE2+nv22rfxUQCNlsde/z4F\n",
      "Pulling data from https://www.sec.state.ma.us/LobbyistPublicSearch/CompleteDisclosure.aspx?sysvalue=qOH5OAu6URrG3qvY0KcrjT8Cd6HIk4OEVgmMDn8i9vU6n8cVsZ6PiBz3uD4tmhUG\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'html_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\geekc\\Code\\jigsaw\\Intern Stuff\\advocacy-maps\\lobbying\\notebooks\\lobbydoodles.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_entity_htmls \u001b[39m=\u001b[39m download_html_list(test_entity_urls)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X32sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m test_lobbyist_htmls \u001b[39m=\u001b[39m download_html_list(test_lobbyist_urls)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#X32sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m html_list\n",
      "\u001b[1;31mNameError\u001b[0m: name 'html_list' is not defined"
     ]
    }
   ],
   "source": [
    "test_entity_htmls = download_html_list(test_entity_urls)\n",
    "test_lobbyist_htmls = download_html_list(test_lobbyist_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = pd.read_html(test_entity_htmls[0])\n",
    "ldf = pd.read_html(test_lobbyist_htmls[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NameAmount  Massachusetts Business Alliance for Education  $6,000.00  The Education Trust Inc  $3,900.00  Total salaries received  $9,900.00'"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[df for df in edf[5:] if 'Client Compensation' in str(df) and len(df) == 2][0][0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NameAmount  Massachusetts Business Alliance for Education  $6,000.00  The Education Trust Inc  $3,900.00  Total salaries received  $9,900.00'"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf[7][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "      <td>No activities, bill numbers or bill titles wer...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  No activities, bill numbers or bill titles wer...   \n",
       "\n",
       "                                                   1  \\\n",
       "0  No activities, bill numbers or bill titles wer...   \n",
       "\n",
       "                                                   2  \\\n",
       "0  No activities, bill numbers or bill titles wer...   \n",
       "\n",
       "                                                   3  \\\n",
       "0  No activities, bill numbers or bill titles wer...   \n",
       "\n",
       "                                                   4  \\\n",
       "0  No activities, bill numbers or bill titles wer...   \n",
       "\n",
       "                                                   5  \n",
       "0  No activities, bill numbers or bill titles wer...  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Massachusetts Medical Society'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldf[8][0][0].split('Client: ')[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Leda  Anderson'"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = ldf[5][0:7].transpose()\n",
    "table.columns = table.iloc[0]\n",
    "table = table[1:]\n",
    "name = table['Lobbyist name'][1]\n",
    "re.sub(\"\\s\\s+\", \" \", name)\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LobbyingDataPage:\n",
    "    def __init__(self, html):\n",
    "        self.tables = {}\n",
    "        self.dfs = pd.read_html(html)\n",
    "        if 'An Error Occurred' in str(self.dfs[0][0]):\n",
    "            #end this. Set default values?\n",
    "            pass\n",
    "        else:\n",
    "            self.is_entity = 'Entity' in self.dfs[4][0][2]\n",
    "            self.get_date_range()\n",
    "            self.get_header()\n",
    "            self.scrape_tables()\n",
    "\n",
    "    def get_date_range(self):\n",
    "        self.date_range = self.dfs[4][0][2].split('period:  ')[1]\n",
    "\n",
    "    #Extracts the table of header info from the top of the page\n",
    "    #TODO merge entites and lobbyists tables??\n",
    "    # add Lobbyist/Entity column\n",
    "    # fill out n/a fields with n/a's\n",
    "    def get_header(self):\n",
    "        table = self.dfs[5][0:7].transpose()\n",
    "        table.columns = table.iloc[0]\n",
    "        table = table[1:]\n",
    "        if self.is_entity:\n",
    "            self.tables['Entities'] = table\n",
    "        else:\n",
    "            self.tables['Lobbyists'] = table\n",
    "\n",
    "    def scrape_tables(self):\n",
    "        for i in range(len(self.dfs[5:])):\n",
    "            df_str = str(self.dfs[i])\n",
    "            #ACTIVITIES TABLES\n",
    "            if 'House / Senate' in df_str and len(self.dfs[i]) == 1:\n",
    "                self.get_activities(i)\n",
    "            \n",
    "            #CLIENT COMPENSATION\n",
    "            if 'Client Compensation' in df_str and len(self.dfs[i]) == 2:\n",
    "                self.get_compensation(i)\n",
    "\n",
    "    def get_activities(self, i):\n",
    "        self.tables.setdefault('Activities', pd.DataFrame()) #Create table if it doesn't exist\n",
    "        client = str(self.dfs[i-1][0][0]).split('Client:')[1].strip()\n",
    "        if self.is_entity:\n",
    "            lobbyist = self.dfs[i-2][0][0].split('Lobbyist:')[1].strip()\n",
    "        else:\n",
    "            lobbyist = str(self.tables['Lobbyists']['Lobbyist name'][1])\n",
    "        table = self.dfs[i+1][:-1]\n",
    "        table.insert(0, 'Client', client)\n",
    "        table.insert(0, 'Lobbyist', lobbyist)\n",
    "        table.insert(0, 'Date Range', self.date_range)\n",
    "        self.tables['Activities'] = pd.concat( [self.tables['Activities'], table])\n",
    "\n",
    "    def get_compensation(self, i):\n",
    "        self.tables.setdefault('Compensation', pd.DataFrame())\n",
    "        comp_str = self.dfs[i][0][1]\n",
    "        data = re.findall(r'[\\w\\s\\.&,]+\\s\\$[\\d,\\.]+', comp_str[11:])\n",
    "        data = [d.split(\" $\") for d in data]\n",
    "        data = [[d[0], float(d[1].replace(',',''))] for d in data if len(d) == 2]\n",
    "        table = pd.DataFrame(data, columns = ['Name', 'Amount'])\n",
    "        self.tables['Compensation'] = pd.concat( [self.tables['Compensation'], table])\n",
    "\n",
    "    def get_salaries(self, i):\n",
    "        pass\n",
    "\n",
    "    def get_operating_expenses(self, i):\n",
    "        pass\n",
    "\n",
    "    def get_entertainment_expenses(self, i):\n",
    "        pass\n",
    "\n",
    "    def get_campaign_contributions(self, i):\n",
    "        pass\n",
    "\n",
    "    def clean_entry(entry):\n",
    "        return re.sub(\"\\s\\s+\", \" \", entry)\n",
    "\n",
    "    def fetch_tables(self):\n",
    "        return self.tables\n",
    "        \n",
    "    def save(self):\n",
    "        for table in self.tables.keys():\n",
    "            self.write_data(f'{table.replace(\" \",\"_\").lower()}.csv', self.tables[table])\n",
    "\n",
    "    def write_data(self, file_path, dataframe):\n",
    "        write = True\n",
    "        #if os.path.exists(file_path):\n",
    "        with open(file_path, mode = 'a', encoding = 'utf-8') as f:\n",
    "            for line in f:\n",
    "                if self.company_name in line and self.date_range in line:\n",
    "                    print('Data already present in ' + file_path)\n",
    "                    write = False\n",
    "                    break\n",
    "\n",
    "        if write and type(dataframe) == pd.DataFrame:\n",
    "            print('Saving data to ' + file_path)\n",
    "            dataframe.to_csv(file_path, mode ='a+',header=(not os.path.exists(file_path)), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NameAmount  PhysicianOne Urgent Care  $61,674.00  ZAFA XXV, LLC  $30,000.00  Massachusetts Aggregate and Asphalt Pavements Association a Division of Construction Industries of Massachusetts  $21,000.00  USA Hauling & Recycling, Inc.  $0.00  Blue Tarp reDevelopment, LLC dba MGM Springfield  $25,000.00  Manafort Brothers Incorporated  $22,916.63  American Medical Response  $60,506.25  Massachusetts Association of Insurance Agents, Inc.  $67,500.00  Massachusetts Municipal Wholesale Electric Company  $54,999.96  Whalley Computer Associates, Inc. $25,000.00  Massachusetts Alliance of Boys & Girls Clubs  $60,166.50  Irish Cultural Center Inc. of Western New England  $4,166.66  Total salaries received  $432,930.00'"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = pd.read_html(test_entity_htmls[1])\n",
    "comp_str = dfs[7][0][1]\n",
    "#df = pd.DataFrame([dfs[7][0][1].split(\"$\")[1:-2:2], dfs[7][0][1].split(\"$\")[2:-2:2]]).transpose()\n",
    "#df.columns = ['Name','Amount']\n",
    "comp_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PhysicianOne Urgent Care</td>\n",
       "      <td>61674.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZAFA XXV, LLC</td>\n",
       "      <td>30000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts Aggregate and Asphalt Pavement...</td>\n",
       "      <td>21000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>USA Hauling &amp; Recycling, Inc.</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blue Tarp reDevelopment, LLC dba MGM Springf...</td>\n",
       "      <td>25000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manafort Brothers Incorporated</td>\n",
       "      <td>22916.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>American Medical Response</td>\n",
       "      <td>60506.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Massachusetts Association of Insurance Agent...</td>\n",
       "      <td>67500.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Massachusetts Municipal Wholesale Electric C...</td>\n",
       "      <td>54999.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Whalley Computer Associates, Inc.</td>\n",
       "      <td>25000.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Massachusetts Alliance of Boys &amp; Girls Clubs</td>\n",
       "      <td>60166.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Irish Cultural Center Inc. of Western New En...</td>\n",
       "      <td>4166.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Total salaries received</td>\n",
       "      <td>432930.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name     Amount\n",
       "0                           PhysicianOne Urgent Care    61674.00\n",
       "1                                      ZAFA XXV, LLC    30000.00\n",
       "2     Massachusetts Aggregate and Asphalt Pavement...   21000.00\n",
       "3                      USA Hauling & Recycling, Inc.        0.00\n",
       "4     Blue Tarp reDevelopment, LLC dba MGM Springf...   25000.00\n",
       "5                     Manafort Brothers Incorporated    22916.63\n",
       "6                          American Medical Response    60506.25\n",
       "7     Massachusetts Association of Insurance Agent...   67500.00\n",
       "8     Massachusetts Municipal Wholesale Electric C...   54999.96\n",
       "9                   Whalley Computer Associates, Inc.   25000.00\n",
       "10      Massachusetts Alliance of Boys & Girls Clubs    60166.50\n",
       "11    Irish Cultural Center Inc. of Western New En...    4166.66\n",
       "12                           Total salaries received   432930.00"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def string_to_dataframe(string):\n",
    "    data = re.findall(r'[\\w\\s\\.&,]+\\s\\$[\\d,\\.]+', string[11:])\n",
    "    data = [d.split(\" $\") for d in data]\n",
    "    data = [[d[0], float(d[1].replace(',',''))] for d in data if len(d) == 2]\n",
    "    df = pd.DataFrame(data, columns = ['Name', 'Amount'])\n",
    "    return df\n",
    "\n",
    "string_to_dataframe(comp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Compensation'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\geekc\\Code\\jigsaw\\Intern Stuff\\advocacy-maps\\lobbying\\notebooks\\lobbydoodles.ipynb Cell 17\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/geekc/Code/jigsaw/Intern%20Stuff/advocacy-maps/lobbying/notebooks/lobbydoodles.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m LobbyingDataPage(test_lobbyist_htmls[\u001b[39m2\u001b[39;49m])\u001b[39m.\u001b[39;49mfetch_tables()[\u001b[39m'\u001b[39;49m\u001b[39mCompensation\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Compensation'"
     ]
    }
   ],
   "source": [
    "LobbyingDataPage(test_lobbyist_htmls[2]).fetch_tables()['Compensation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "tables = {}\n",
    "for i in range(len(edf)):\n",
    "    if ('House / Senate' in str(edf[i]) and len(edf[i]) == 1):\n",
    "        print(i)\n",
    "        tables.setdefault('Activities', pd.DataFrame())\n",
    "        client = edf[i-1][0][0].split('Client:')[1].strip()\n",
    "        table = edf[i+1][:-1]\n",
    "        tables['Activities'] = pd.concat( [tables['Activities'], edf[i+1][:-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing index 48\n",
      "Error processing index 54\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(html05)):\n",
    "    dfs = pd.read_html(html05[i])\n",
    "    is_error = 'An Error Occurred' in str(dfs[0][0])\n",
    "    if is_error:\n",
    "        print(f'Error processing index {i}')\n",
    "        #Return\n",
    "    else: #Remove\n",
    "        is_entity = 'Entity' in dfs[4][0][2]\n",
    "        header_table = dfs[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Header:\n",
    "# Authorizing Officer name / Lobbyist name\n",
    "# Title / NA\n",
    "# Business name / Business name\n",
    "# Address / Address\n",
    "# City, state, zip code / Citym, state, zip code\n",
    "# country / country\n",
    "# NA / Agent Type\n",
    "\n",
    "#TABLES:\n",
    "# Entities\n",
    "# Lobbyists\n",
    "# Client Compensation\n",
    "# Compensation/Salaries Paid\n",
    "# Activities, Bill Numbers and Titles\n",
    "# Operating Expenses\n",
    "# Meals, Travel, and Entertainment Expenses\n",
    "# Additional Expenses\n",
    "# Campaign Contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "300fbccfaa1afd04bb86653fbdee52f26c731e37f5150715ebdacf05ee18f2ba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
